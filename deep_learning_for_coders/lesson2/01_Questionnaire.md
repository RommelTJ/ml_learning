# Questionnaire

1. Can we always use a random sample for a validation set? Why or why not?
2. What is overfitting? Provide an example.
3. What is a metric? How does it differ from "loss"?
4. How can pretrained models help?
5. What is the "head" of a model?
6. What kinds of features do the early layers of a CNN find? How about the later layers?
7. Are image models only useful for photos?
8. What is an "architecture"?
9. What is segmentation?
10. What is y_range used for? When do we need it?
11. What are "hyperparameters"?
12. What's the best way to avoid failures when using AI in an organization?
13. What is a p value?
14. What is a prior?
15. Provide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data.
16. Where do text models currently have a major deficiency?
17. What are possible negative societal implications of text generation models?
18. In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?
19. What kind of tabular data is deep learning particularly good at?
20. What's a key downside of directly using a deep learning model for recommendation systems?
21. What are the steps of the Drivetrain Approach?
22. How do the steps of the Drivetrain Approach map to a recommendation system?
23. Create an image recognition model using data you curate, and deploy it on the web.
24. What is DataLoaders?
25. What four things do we need to tell fastai to create DataLoaders?
26. What does the splitter parameter to DataBlock do?
27. How do we ensure a random split always gives the same validation set?
